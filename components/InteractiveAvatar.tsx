/**
 * ================================================
 * InteractiveAvatar.tsx - ì¹˜ë§¤ì˜ˆë°© ê²Œì„ AI ì•„ë°”íƒ€
 * ================================================
 *
 * ğŸ†• 2026-01-22 ì—…ë°ì´íŠ¸: ìŒì„± ëª…ë ¹ ê¸°ë°˜ ê²Œì„ ì œì–´
 * ğŸ”§ 2026-01-22 ìˆ˜ì •: ì˜ë„ ë¶„ì„ ë¡œì§ ê°œì„ 
 *    - "ì‹¤í–‰", "ì—´ì–´", "ì¼œì¤˜" ë“± í‚¤ì›Œë“œ ì¶”ê°€
 *    - UI_CONTROL ë¨¼ì € ì²´í¬í•˜ë„ë¡ ìˆœì„œ ë³€ê²½
 *    - confidence threshold ì¡°ì •
 * 
 * ê¸°ëŠ¥:
 * 1. ìŒì„± ëª…ë ¹ â†’ Intent Recognition â†’ ê²Œì„/UI ìë™ ì œì–´
 * 2. ì¼ë°˜ ëŒ€í™” â†’ OpenAI â†’ ì‘ë‹µ ìƒì„±
 * 3. postMessageë¡œ index.htmlê³¼ ì–‘ë°©í–¥ í†µì‹ 
 *
 * í•µì‹¬: ì•„ë°”íƒ€ê°€ ë§í•  ë•Œ Web Speech ì¼ì‹œì •ì§€ â†’ ìê¸° ëª©ì†Œë¦¬ ì¸ì‹ ë°©ì§€
 * ================================================
 */

import {
  AvatarQuality,
  StreamingEvents,
  VoiceEmotion,
  StartAvatarRequest,
  TaskType,
} from "@heygen/streaming-avatar";
import { useEffect, useRef, useState, useCallback } from "react";
import { useMemoizedFn, useUnmount } from "ahooks";

import { useStreamingAvatarSession } from "./logic/useStreamingAvatarSession";
import { StreamingAvatarProvider, StreamingAvatarSessionState } from "./logic";
import { AVATARS } from "@/app/lib/constants";
import { WebSpeechRecognizer } from "@/app/lib/webSpeechAPI";

// ============================================
// ğŸ†• ìŒì„± ëª…ë ¹ ì˜ë„ ë¶„ì„ ì‹œìŠ¤í…œ (ìˆ˜ì •ë¨)
// ============================================

interface VoiceIntent {
  type: 'GAME_START' | 'UI_CONTROL' | 'INFO_REQUEST' | 'GENERAL_CHAT';
  action?: string;
  game?: string;
  confidence: number;
}

// ëª…ë ¹ì–´ íŒ¨í„´ ì •ì˜ (í•œêµ­ì–´ ìì—°ì–´ ë³€í˜• í¬í•¨)
const VOICE_COMMAND_PATTERNS = {
  // ê²Œì„ ì‹œì‘ ëª…ë ¹
  GAME_START: {
    hwatu: [
      'í™”íˆ¬', 'ì¹´ë“œ', 'ì§ë§ì¶”ê¸°', 'ì§ ë§ì¶”ê¸°', 'ì¹´ë“œê²Œì„', 'ì¹´ë“œ ê²Œì„',
      'í™”íˆ¬ ì‹œì‘', 'ì¹´ë“œ ì‹œì‘', 'ì§ë§ì¶”ê¸° ì‹œì‘', 'ì§ë§ì¶”ê¸° í•´', 'ì§ë§ì¶”ê¸° í•˜ì',
      'í™”íˆ¬ ê²Œì„', 'ì¹´ë“œì§', 'ê·¸ë¦¼ ë§ì¶”ê¸°'
    ],
    pattern: [
      'ìƒ‰ìƒ', 'íŒ¨í„´', 'ìƒ‰ê¹”', 'ìƒ‰ìƒ íŒ¨í„´', 'ìƒ‰ê¹” ê¸°ì–µ', 'ìƒ‰ìƒ ê²Œì„', 'íŒ¨í„´ ê²Œì„',
      'ìƒ‰ìƒ ì‹œì‘', 'íŒ¨í„´ ì‹œì‘', 'ìƒ‰ê¹” ë§ì¶”ê¸°', 'ì‚¬ì´ë¨¼', 'ìƒ‰ê¹” ìˆœì„œ'
    ],
    memory: [
      'ìˆ«ì', 'ìˆ«ì ê¸°ì–µ', 'ìˆ«ì ì™¸ìš°ê¸°', 'ìˆ«ì ê²Œì„', 'ìˆ«ì ë§ì¶”ê¸°',
      'ìˆ«ì ì‹œì‘', 'ìˆ«ì ê¸°ì–µí•˜ê¸°', 'ìˆ«ì ì™¸ìš°ê¸° í•˜ì', 'ë²ˆí˜¸ ê¸°ì–µ'
    ],
    proverb: [
      'ì†ë‹´', 'ì†ë‹´ ì™„ì„±', 'ì†ë‹´ ê²Œì„', 'ì†ë‹´ ë§ì¶”ê¸°', 'ì†ë‹´ ì‹œì‘',
      'ì†ë‹´ ì™„ì„±í•˜ê¸°', 'ì†ë‹´ í•˜ì', 'ì˜›ë§', 'ê²©ì–¸'
    ],
    calc: [
      'ê³„ì‚°', 'ì‚°ìˆ˜', 'ë§ì…ˆ', 'ëº„ì…ˆ', 'ê³„ì‚° ê²Œì„', 'ì‚°ìˆ˜ ê²Œì„',
      'ê³„ì‚° ì‹œì‘', 'ì‚°ìˆ˜ ì‹œì‘', 'ê³„ì‚° í•˜ì', 'ì‚°ìˆ˜ í•˜ì', 'ìˆ˜í•™', 'ë”í•˜ê¸° ë¹¼ê¸°',
      'ì‚°ìˆ˜ ê³„ì‚°'  // ğŸ†• ì¶”ê°€
    ],
    sequence: [
      'ìˆœì„œ', 'ìˆœì„œ ë§ì¶”ê¸°', 'ê·¸ë¦¼ ìˆœì„œ', 'ìˆœì„œ ê²Œì„', 'ìˆœì„œ ì‹œì‘',
      'ìˆœì„œ ë§ì¶”ê¸° í•˜ì', 'ìˆœì„œ ì •í•˜ê¸°', 'ì°¨ë¡€', 'ë°°ì—´'
    ]
  },
  
  // UI ì œì–´ ëª…ë ¹
  UI_CONTROL: {
    SHOW_MY_RECORDS: [
      'ë‚´ ì ìˆ˜', 'ë‚´ ê¸°ë¡', 'ì ìˆ˜ ë³´ì—¬', 'ê¸°ë¡ ë³´ì—¬', 'ë‚´ ì ìˆ˜ ë³´ì—¬ì¤˜',
      'ì ìˆ˜ í™•ì¸', 'ë‚´ ì„±ì ', 'ì„±ì  ë³´ì—¬ì¤˜', 'ë‚´ ê¸°ë¡ ë³´ì—¬ì¤˜', 'ì ìˆ˜ ì°½'
    ],
    SHOW_DASHBOARD: [
      'ëŒ€ì‹œë³´ë“œ', 'ì¸ì§€ ë¶„ì„', 'ë‘ë‡Œ ê±´ê°•', 'ë¶„ì„ ë³´ì—¬ì¤˜', 'ì¸ì§€ ì ìˆ˜',
      'ë‘ë‡Œ ë¶„ì„', 'ê±´ê°• ë¶„ì„', 'ì¸ì§€ ëŠ¥ë ¥', 'ë‡Œ ê±´ê°•'
    ],
    SHOW_RANKING: [
      'ë­í‚¹', 'ìˆœìœ„', '1ë“±', 'ì¼ë“±', 'ë­í‚¹ ë³´ì—¬ì¤˜', 'ìˆœìœ„ ë³´ì—¬ì¤˜',
      'ëˆ„ê°€ 1ë“±', 'ì „ì²´ ìˆœìœ„', 'ë­í‚¹ ì°½', 'ë“±ìˆ˜'
    ],
    CLOSE_MODAL: [
      'ë‹«ì•„', 'ë‹«ê¸°', 'ë‚˜ê°€', 'ë‚˜ê°€ê¸°', 'ë’¤ë¡œ', 'ë’¤ë¡œê°€ê¸°', 'ì°½ ë‹«ì•„',
      'ê·¸ë§Œ', 'ë', 'ì¢…ë£Œ', 'ì·¨ì†Œ', 'ëŒì•„ê°€'
    ],
    SAVE_SCORE: [
      'ì €ì¥', 'ì €ì¥í•´', 'ì €ì¥í•´ì¤˜', 'ê¸°ë¡ ì €ì¥', 'ì ìˆ˜ ì €ì¥',
      'ì„¸ì´ë¸Œ', 'ì €ì¥í•˜ì', 'ì €ì¥ í•´ì¤˜'
    ]
  },
  
  // ì •ë³´ ìš”ì²­ (ê¸°ì¡´ LLM ì²˜ë¦¬) - action í‚¤ì›Œë“œ ê°ì§€ìš©
  INFO_REQUEST: [
    'ì ìˆ˜ ì•Œë ¤ì¤˜', 'ì˜¤ëŠ˜ ëª‡ì ', 'ìµœê³  ì ìˆ˜', 'í‰ê·  ì ìˆ˜',
    'ëª‡ë²ˆ í–ˆì–´', 'ë©°ì¹ ì§¸', 'ì„¤ëª…í•´ì¤˜', 'ì–´ë–»ê²Œ í•´', 'ë°©ë²• ì•Œë ¤ì¤˜',
    'ê·œì¹™ì´ ë­ì•¼', 'ì–´ë–»ê²Œ í•˜ëŠ” ê±°ì•¼'
  ]
};

// ğŸ†• ê²Œì„ ì‹œì‘ ë™ì‘ í‚¤ì›Œë“œ (í™•ì¥ë¨!)
const GAME_ACTION_KEYWORDS = [
  'ì‹œì‘', 'í•˜ì', 'í•´ì¤˜', 'í•´', 'í• ë˜', 'í•˜ê³  ì‹¶ì–´', 'í•´ë³¼ë˜', 'í•˜ê³ ì‹¶ì–´',
  'ì‹¤í–‰', 'ì—´ì–´', 'ì¼œì¤˜', 'ì¼œ', 'í”Œë ˆì´', 'ê²Œì„', 'ê³ ', 'go', 'í•´ë³´ì',
  'ì—´ì–´ì¤˜', 'ì‹œì‘í•´', 'ì‹œì‘í•´ì¤˜', 'í•´ë´', 'í•´ ë´', 'ì‹œì‘í•˜ì'
];

// ê²Œì„ í•œê¸€ëª… ë§¤í•‘
const GAME_NAMES: Record<string, string> = {
  hwatu: 'í™”íˆ¬ ì§ë§ì¶”ê¸°',
  pattern: 'ìƒ‰ìƒ íŒ¨í„´ ê¸°ì–µ',
  memory: 'ìˆ«ì ê¸°ì–µí•˜ê¸°',
  proverb: 'ì†ë‹´ ì™„ì„±í•˜ê¸°',
  calc: 'ì‚°ìˆ˜ ê³„ì‚°',
  sequence: 'ìˆœì„œ ë§ì¶”ê¸°'
};

// UI ì•¡ì…˜ë³„ ì‘ë‹µ ë©”ì‹œì§€
const UI_RESPONSES: Record<string, string> = {
  'SHOW_MY_RECORDS': 'ë„¤, ê¸°ë¡ì„ ë³´ì—¬ë“œë¦´ê²Œìš”.',
  'SHOW_DASHBOARD': 'ì¸ì§€ ë¶„ì„ ëŒ€ì‹œë³´ë“œë¥¼ ì—´ì–´ë“œë¦´ê²Œìš”.',
  'SHOW_RANKING': 'ì „ì²´ ë­í‚¹ì„ ë³´ì—¬ë“œë¦´ê²Œìš”.',
  'CLOSE_MODAL': 'ë„¤, ì°½ì„ ë‹«ì„ê²Œìš”.',
  'SAVE_SCORE': 'ì ìˆ˜ë¥¼ ì €ì¥í• ê²Œìš”.'
};

/**
 * ğŸ†• ìŒì„± ì…ë ¥ì—ì„œ ì˜ë„ë¥¼ ë¶„ì„í•˜ëŠ” í•¨ìˆ˜ (ìˆ˜ì •ë¨!)
 * 
 * ìˆœì„œ: UI_CONTROL â†’ GAME_START â†’ INFO_REQUEST â†’ GENERAL_CHAT
 * (UI ì œì–´ë¥¼ ë¨¼ì € ì²´í¬í•˜ì—¬ "ë­í‚¹"ì´ ê²Œì„ ì‹œì‘ìœ¼ë¡œ ì˜¤ì¸ë˜ì§€ ì•Šë„ë¡)
 */
function analyzeVoiceIntent(transcript: string): VoiceIntent {
  const normalizedText = transcript
    .toLowerCase()
    .replace(/\s+/g, ' ')
    .trim();
  
  console.log('[ğŸ” Intent Analysis] Input:', normalizedText);
  
  // â­ 1. UI ì œì–´ ëª…ë ¹ ë¨¼ì € ì²´í¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ!)
  for (const [action, keywords] of Object.entries(VOICE_COMMAND_PATTERNS.UI_CONTROL)) {
    for (const keyword of keywords) {
      if (normalizedText.includes(keyword)) {
        console.log('[ğŸ” Intent Analysis] UI_CONTROL matched:', action, 'keyword:', keyword);
        return {
          type: 'UI_CONTROL',
          action: action,
          confidence: 0.95
        };
      }
    }
  }
  
  // 2. ê²Œì„ ì‹œì‘ ëª…ë ¹ ì²´í¬
  for (const [game, keywords] of Object.entries(VOICE_COMMAND_PATTERNS.GAME_START)) {
    for (const keyword of keywords) {
      if (normalizedText.includes(keyword)) {
        // ğŸ†• í™•ì¥ëœ ë™ì‘ í‚¤ì›Œë“œ ì²´í¬
        const hasActionWord = GAME_ACTION_KEYWORDS.some(action => normalizedText.includes(action));
        
        // ê²Œì„ ì´ë¦„ë§Œ ë§í•´ë„ ì‹œì‘ ì˜ë„ë¡œ ì¸ì‹ (ì–´ë¥´ì‹  í¸ì˜ì„±)
        // ë‹¨, ë„ˆë¬´ ì§§ì€ ë‹¨ì–´(ì˜ˆ: "ìˆ«ì", "ê³„ì‚°")ëŠ” ë™ì‘ í‚¤ì›Œë“œ í•„ìš”
        const isShortKeyword = keyword.length <= 2;
        
        // ğŸ†• ê²Œì„ ê´€ë ¨ í‚¤ì›Œë“œê°€ ëª…í™•í•˜ë©´ ë°”ë¡œ ì¸ì‹
        const isExplicitGameKeyword = keyword.includes('ê²Œì„') || keyword.includes('ì‹œì‘');
        
        if (hasActionWord || isExplicitGameKeyword || (!isShortKeyword && keywords.slice(0, 3).some(k => normalizedText.includes(k)))) {
          console.log('[ğŸ” Intent Analysis] GAME_START matched:', game, 'keyword:', keyword, 'hasAction:', hasActionWord);
          return {
            type: 'GAME_START',
            action: `START_GAME_${game.toUpperCase()}`,
            game: game,
            confidence: hasActionWord ? 0.95 : 0.85
          };
        }
      }
    }
  }
  
  // 3. ì •ë³´ ìš”ì²­ ì²´í¬ (ê¸°ì¡´ LLMìœ¼ë¡œ ì²˜ë¦¬)
  for (const keyword of VOICE_COMMAND_PATTERNS.INFO_REQUEST) {
    if (normalizedText.includes(keyword)) {
      console.log('[ğŸ” Intent Analysis] INFO_REQUEST matched:', keyword);
      return {
        type: 'INFO_REQUEST',
        confidence: 0.85
      };
    }
  }
  
  // 4. ì¼ë°˜ ëŒ€í™”
  console.log('[ğŸ” Intent Analysis] GENERAL_CHAT (default)');
  return {
    type: 'GENERAL_CHAT',
    confidence: 0.7
  };
}

// ============================================
// ì•„ë°”íƒ€ ì„¤ì •
// ============================================
const AVATAR_CONFIG: StartAvatarRequest = {
  quality: AvatarQuality.Low,
  avatarName: AVATARS[0].avatar_id,
  voice: {
    rate: 1.2,
    emotion: VoiceEmotion.FRIENDLY,
  },
  language: "ko",
};

interface ChatMessage {
  role: "user" | "assistant";
  content: string;
}

function InteractiveAvatar() {
  const {
    initAvatar,
    startAvatar,
    stopAvatar,
    sessionState,
    stream,
    avatarRef,
  } = useStreamingAvatarSession();

  // UI ìƒíƒœ
  const [inputText, setInputText] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [chatHistory, setChatHistory] = useState<ChatMessage[]>([]);
  const [isListening, setIsListening] = useState(false);
  const [isAvatarSpeaking, setIsAvatarSpeaking] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState("");
  const mediaStream = useRef<HTMLVideoElement>(null);

  // ë‚´ë¶€ ìƒíƒœ refs
  const isProcessingRef = useRef(false);
  const hasGreetedRef = useRef(false);
  const hasStartedRef = useRef(false);
  const userNameRef = useRef<string>("");
  const userStatsRef = useRef<any>(null);

  // Web Speech API ref
  const webSpeechRef = useRef<WebSpeechRecognizer | null>(null);
  const isAvatarSpeakingRef = useRef(false);

  // ============================================
  // API í˜¸ì¶œ
  // ============================================
  const fetchAccessToken = async () => {
    const response = await fetch("/api/get-access-token", { method: "POST" });
    const token = await response.text();
    console.log("Access Token:", token);
    return token;
  };

  // ğŸ¯ LLM API í˜¸ì¶œ (ì±„íŒ…, ì¸ì‚¬ë§, ê²Œì„ì„¤ëª…)
  const callChatAPI = async (
    type: string,
    data: Record<string, any>
  ): Promise<string> => {
    try {
      const response = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          type,
          ...data,
          userName: userNameRef.current,
        }),
      });
      const result = await response.json();
      return result.reply || "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.";
    } catch (error) {
      console.error("Chat API error:", error);
      return "ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.";
    }
  };

  // ============================================
  // ğŸ†• ë¶€ëª¨ ì°½(index.html)ì— ìŒì„± ëª…ë ¹ ì „ì†¡
  // ============================================
  const sendVoiceCommand = useCallback((action: string, game?: string) => {
    console.log("ğŸ“¤ Sending VOICE_COMMAND:", { action, game });
    window.parent.postMessage({
      type: 'VOICE_COMMAND',
      action: action,
      game: game,
      timestamp: Date.now()
    }, '*');
  }, []);

  // ============================================
  // ì•„ë°”íƒ€ ìŒì„± ì¶œë ¥ (Web Speech ì¼ì‹œì •ì§€ í¬í•¨)
  // ============================================
  const speakWithAvatar = useCallback(
    async (text: string) => {
      if (!avatarRef.current || !text) return;

      try {
        // ğŸ”‡ Web Speech ì™„ì „íˆ ì •ì§€
        console.log("ğŸ”‡ Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();

        // ì ì‹œ ëŒ€ê¸° (Web Speechê°€ ì™„ì „íˆ ë©ˆì¶œ ë•Œê¹Œì§€)
        await new Promise((r) => setTimeout(r, 300));

        // HeyGen ìë™ ì‘ë‹µ ì°¨ë‹¨
        try {
          await avatarRef.current.interrupt();
        } catch {
          // ignore
        }

        console.log("ğŸ—£ï¸ Avatar speaking:", text);
        await avatarRef.current.speak({
          text,
          taskType: TaskType.REPEAT,
        });
      } catch (error) {
        console.error("Avatar speak error:", error);
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);
        webSpeechRef.current?.resume();
      }
    },
    [avatarRef]
  );

  // ============================================
  // ğŸ†• ì‚¬ìš©ì ìŒì„± ì²˜ë¦¬ (Intent Recognition í¬í•¨) - ìˆ˜ì •ë¨!
  // ============================================
  const handleUserSpeech = useCallback(
    async (transcript: string) => {
      // ì•„ë°”íƒ€ê°€ ë§í•˜ëŠ” ì¤‘ì´ë©´ ë¬´ì‹œ
      if (isAvatarSpeakingRef.current) {
        console.log("â¸ï¸ ì•„ë°”íƒ€ê°€ ë§í•˜ëŠ” ì¤‘ - ë¬´ì‹œ:", transcript);
        return;
      }

      if (!transcript.trim() || isProcessingRef.current) return;

      isProcessingRef.current = true;
      setIsLoading(true);
      setInterimTranscript("");
      console.log("ğŸ¯ User said:", transcript);

      try {
        // ğŸ†• ì˜ë„ ë¶„ì„
        const intent = analyzeVoiceIntent(transcript);
        console.log('[Voice Intent Result]', intent);

        switch (intent.type) {
          case 'GAME_START':
            // ğŸ†• ë¨¼ì € ë¶€ëª¨ ì°½ì— ê²Œì„ ì‹œì‘ ëª…ë ¹ ì „ì†¡!
            sendVoiceCommand(intent.action!, intent.game);
            
            // ê·¸ ë‹¤ìŒ ì•„ë°”íƒ€ê°€ ì‘ë‹µ
            const gameName = GAME_NAMES[intent.game!] || intent.game;
            const gameResponse = `ë„¤! ${gameName} ê²Œì„ì„ ì‹œì‘í• ê²Œìš”. í™”ì´íŒ…!`;
            
            setChatHistory(prev => [
              ...prev,
              { role: "user", content: transcript },
              { role: "assistant", content: gameResponse }
            ]);
            
            await speakWithAvatar(gameResponse);
            break;

          case 'UI_CONTROL':
            // ë¶€ëª¨ ì°½ì— UI ì œì–´ ëª…ë ¹ ì „ì†¡
            sendVoiceCommand(intent.action!);
            
            // ì•„ë°”íƒ€ ì‘ë‹µ
            const uiResponse = UI_RESPONSES[intent.action!] || 'ì•Œê² ìŠµë‹ˆë‹¤.';
            
            setChatHistory(prev => [
              ...prev,
              { role: "user", content: transcript },
              { role: "assistant", content: uiResponse }
            ]);
            
            await speakWithAvatar(uiResponse);
            break;

          case 'INFO_REQUEST':
          case 'GENERAL_CHAT':
          default:
            // ê¸°ì¡´ LLM ëŒ€í™” ì²˜ë¦¬
            setChatHistory(prev => [
              ...prev,
              { role: "user", content: transcript }
            ]);

            const reply = await callChatAPI('chat', {
              message: transcript,
              history: chatHistory
            });
            
            setChatHistory(prev => [
              ...prev,
              { role: "assistant", content: reply }
            ]);
            
            await speakWithAvatar(reply);
            break;
        }
      } catch (error) {
        console.error('[Voice Command Error]', error);
        await speakWithAvatar('ì£„ì†¡í•´ìš”, ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”.');
      } finally {
        setIsLoading(false);
        isProcessingRef.current = false;
      }
    },
    [speakWithAvatar, sendVoiceCommand, chatHistory]
  );

  // ============================================
  // Web Speech API ì´ˆê¸°í™”
  // ============================================
  const initWebSpeech = useCallback(() => {
    if (webSpeechRef.current) {
      console.log("ğŸ¤ Web Speech ì´ë¯¸ ì´ˆê¸°í™”ë¨");
      return;
    }

    if (!WebSpeechRecognizer.isSupported()) {
      console.error("ğŸ¤ Web Speech API ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €");
      return;
    }

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì¤‘...");

    webSpeechRef.current = new WebSpeechRecognizer(
      {
        onResult: (transcript: string, isFinal: boolean) => {
          if (isAvatarSpeakingRef.current) {
            return;
          }

          if (isFinal) {
            console.log("ğŸ¤ ìµœì¢… ì¸ì‹:", transcript);
            setInterimTranscript("");
            handleUserSpeech(transcript);
          } else {
            setInterimTranscript(transcript);
          }
        },

        onStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onEnd: () => {
          setIsListening(false);
        },

        onSpeechStart: () => {
          if (!isAvatarSpeakingRef.current) {
            setIsListening(true);
          }
        },

        onSpeechEnd: () => {
          setTimeout(() => {
            if (!isAvatarSpeakingRef.current) {
              setIsListening(false);
            }
          }, 500);
        },

        onError: (error: string) => {
          console.error("ğŸ¤ Web Speech ì—ëŸ¬:", error);
          if (error === "not-allowed") {
            alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.");
          }
        },
      },
      {
        lang: "ko-KR",
        continuous: true,
        interimResults: true,
        autoRestart: true,
      }
    );

    console.log("ğŸ¤ Web Speech API ì´ˆê¸°í™” ì™„ë£Œ");
  }, [handleUserSpeech]);

  // ============================================
  // ì„¸ì…˜ ì´ˆê¸°í™”
  // ============================================
  const resetSession = useMemoizedFn(async () => {
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì¤‘...");

    // Web Speech ì •ë¦¬
    if (webSpeechRef.current) {
      webSpeechRef.current.destroy();
      webSpeechRef.current = null;
    }

    // HeyGen ì„¸ì…˜ ì •ë¦¬
    try {
      if (avatarRef.current) {
        await avatarRef.current.stopAvatar();
      }
    } catch (e) {
      console.log("stopAvatar ì—ëŸ¬ (ë¬´ì‹œ):", e);
    }

    try {
      await stopAvatar();
    } catch (e) {
      console.log("stopAvatar hook ì—ëŸ¬ (ë¬´ì‹œ):", e);
    }

    // ìƒíƒœ ì´ˆê¸°í™”
    hasStartedRef.current = false;
    hasGreetedRef.current = false;
    isProcessingRef.current = false;
    isAvatarSpeakingRef.current = false;
    userNameRef.current = "";
    userStatsRef.current = null;
    setChatHistory([]);
    setIsLoading(false);
    setIsListening(false);
    setIsAvatarSpeaking(false);
    setInterimTranscript("");

    await new Promise((r) => setTimeout(r, 1000));
    console.log("ğŸ”„ ì„¸ì…˜ ì´ˆê¸°í™” ì™„ë£Œ");
  });

  // ============================================
  // ì„¸ì…˜ ì‹œì‘
  // ============================================
  const startSession = useMemoizedFn(async () => {
    if (hasStartedRef.current) {
      console.log("âš ï¸ ì´ë¯¸ ì„¸ì…˜ ì‹œì‘ë¨, ë¬´ì‹œ");
      return;
    }
    hasStartedRef.current = true;

    try {
      const token = await fetchAccessToken();
      const avatar = initAvatar(token);

      avatar.on(StreamingEvents.STREAM_READY, async (event) => {
        console.log("Stream ready:", event.detail);

        if (!hasGreetedRef.current) {
          await new Promise((r) => setTimeout(r, 1500));

          // ì¸ì‚¬ë§ ìƒì„±
          const userName = userNameRef.current;
          let greeting: string;
          
          if (userName) {
            greeting = await callChatAPI('greeting', { userName });
          } else {
            greeting = "ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” ë‘ë‡Œ ê±´ê°• ë„ìš°ë¯¸ì˜ˆìš”. 'ì‚°ìˆ˜ ê³„ì‚° ê²Œì„ ì‹¤í–‰'ì´ë‚˜ 'ë‚´ ì ìˆ˜ ë³´ì—¬ì¤˜'ì²˜ëŸ¼ ë§ì”€í•´ ì£¼ì„¸ìš”!";
          }

          console.log("ğŸ‘‹ ì¸ì‚¬ë§:", greeting);
          await speakWithAvatar(greeting);
          setChatHistory([{ role: "assistant", content: greeting }]);
          hasGreetedRef.current = true;
        }
      });

      avatar.on(StreamingEvents.STREAM_DISCONNECTED, () => {
        console.log("Stream disconnected");
        hasGreetedRef.current = false;
        hasStartedRef.current = false;

        webSpeechRef.current?.destroy();
        webSpeechRef.current = null;
      });

      avatar.on(StreamingEvents.AVATAR_START_TALKING, () => {
        console.log("ğŸ—£ï¸ Avatar started talking - Web Speech ì¼ì‹œì •ì§€");
        isAvatarSpeakingRef.current = true;
        setIsAvatarSpeaking(true);
        webSpeechRef.current?.pause();
      });

      avatar.on(StreamingEvents.AVATAR_STOP_TALKING, async () => {
        console.log("ğŸ”ˆ Avatar stopped talking - Web Speech ì¬ê°œ");
        isAvatarSpeakingRef.current = false;
        setIsAvatarSpeaking(false);

        await new Promise((r) => setTimeout(r, 500));
        webSpeechRef.current?.resume();
        console.log("ğŸ¤ Web Speech ì¬ê°œ ì™„ë£Œ");
      });

      await startAvatar(AVATAR_CONFIG);

      console.log("ğŸ¤ Web Speech API ì‹œì‘...");
      initWebSpeech();

      setTimeout(() => {
        webSpeechRef.current?.start();
        console.log("ğŸ¤ Web Speech ì¸ì‹ ì‹œì‘");
      }, 2000);
    } catch (error) {
      console.error("Session error:", error);
      hasStartedRef.current = false;
    }
  });

  // ============================================
  // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
  // ============================================
  const handleSendMessage = useMemoizedFn(async () => {
    const text = inputText.trim();
    if (!text || !avatarRef.current || isLoading) return;

    setInputText("");
    
    // í…ìŠ¤íŠ¸ ì…ë ¥ë„ ìŒì„±ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
    await handleUserSpeech(text);
  });

  // ============================================
  // ë§ˆì´í¬ í† ê¸€ ë²„íŠ¼ í•¸ë“¤ëŸ¬
  // ============================================
  const toggleMicrophone = useCallback(() => {
    if (!webSpeechRef.current) {
      initWebSpeech();
      setTimeout(() => {
        webSpeechRef.current?.start();
      }, 100);
      return;
    }

    if (webSpeechRef.current.getIsPaused()) {
      webSpeechRef.current.resume();
    } else {
      webSpeechRef.current.pause();
    }
  }, [initWebSpeech]);

  // ============================================
  // postMessage í†µì‹  (ë©”ì¸ í˜ì´ì§€ì™€)
  // ============================================
  useEffect(() => {
    const handleMessage = async (event: MessageEvent) => {
      const { type, name, stats, game } = event.data || {};
      console.log("ğŸ“¥ Received message:", { type, name, game });

      switch (type) {
        case "RESET_AVATAR":
        case "STOP_AVATAR":
          await resetSession();
          break;

        case "START_AVATAR":
          await resetSession();
          if (name) userNameRef.current = name;
          if (stats) userStatsRef.current = stats;
          startSession();
          break;

        case "EXPLAIN_GAME":
          if (avatarRef.current && game) {
            const explanation = await callChatAPI("game_explain", { game });
            await speakWithAvatar(explanation);
          }
          break;

        case "EXPLAIN_DASHBOARD":
          if (avatarRef.current) {
            const explanation = await callChatAPI("dashboard_explain", event.data);
            await speakWithAvatar(explanation);
          }
          break;
          
        case "USER_INFO":
          if (name) userNameRef.current = name;
          break;
      }
    };

    window.addEventListener("message", handleMessage);
    return () => window.removeEventListener("message", handleMessage);
  }, [resetSession, startSession, speakWithAvatar]);

  // ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useUnmount(() => {
    webSpeechRef.current?.destroy();
    try {
      stopAvatar();
    } catch {
      // ignore
    }
  });

  // í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨/ë‹«ê¸° ì „ ì„¸ì…˜ ì •ë¦¬
  useEffect(() => {
    const handleBeforeUnload = () => {
      console.log("ğŸ”„ beforeunload - ì„¸ì…˜ ì •ë¦¬ ì¤‘...");
      if (webSpeechRef.current) {
        webSpeechRef.current.destroy();
        webSpeechRef.current = null;
      }
      if (avatarRef.current) {
        try {
          avatarRef.current.stopAvatar();
        } catch {
          // ignore
        }
      }
    };

    window.addEventListener("beforeunload", handleBeforeUnload);
    return () => window.removeEventListener("beforeunload", handleBeforeUnload);
  }, [avatarRef]);

  // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—°ê²°
  useEffect(() => {
    if (stream && mediaStream.current) {
      mediaStream.current.srcObject = stream;
      mediaStream.current.onloadedmetadata = () => mediaStream.current?.play();
    }
  }, [stream]);

  // ============================================
  // UI
  // ============================================
  const getStatusText = () => {
    if (isAvatarSpeaking) return "ë§í•˜ëŠ” ì¤‘...";
    if (isListening) return "ë“£ê³  ìˆì–´ìš” ğŸ¤";
    if (isLoading) return "ìƒê° ì¤‘...";
    return "ë§ì”€í•˜ì„¸ìš”";
  };

  const getStatusColor = () => {
    if (isAvatarSpeaking) return "bg-blue-500";
    if (isListening) return "bg-red-500 animate-pulse";
    if (isLoading) return "bg-yellow-500";
    return "bg-green-500";
  };

  return (
    <div className="w-full h-full flex flex-col">
      {sessionState === StreamingAvatarSessionState.CONNECTED && stream ? (
        <div className="flex-1 relative flex flex-col">
          <div className="relative flex-shrink-0">
            <video
              ref={mediaStream}
              autoPlay
              playsInline
              style={{ display: "block", width: "100%", height: "auto" }}
            />

            {/* ì¢…ë£Œ ë²„íŠ¼ */}
            <button
              className="absolute top-2 right-2 w-7 h-7 bg-black/50 hover:bg-red-600 text-white rounded-full flex items-center justify-center text-xs"
              onClick={() => resetSession()}
            >
              âœ•
            </button>

            {/* ë§ˆì´í¬ í† ê¸€ ë²„íŠ¼ */}
            <button
              className={`absolute top-2 left-2 w-7 h-7 ${
                isListening
                  ? "bg-red-500 animate-pulse"
                  : "bg-black/50 hover:bg-green-600"
              } text-white rounded-full flex items-center justify-center text-sm`}
              disabled={isAvatarSpeaking}
              title={isListening ? "ë§ˆì´í¬ ë„ê¸°" : "ë§ˆì´í¬ ì¼œê¸°"}
              onClick={toggleMicrophone}
            >
              {isListening ? "ğŸ¤" : "ğŸ™ï¸"}
            </button>

            {/* ìƒíƒœ í‘œì‹œ */}
            <div className="absolute bottom-2 left-2 flex items-center gap-2">
              <div className={`w-3 h-3 rounded-full ${getStatusColor()}`} />
              <span className="text-white text-xs bg-black/50 px-2 py-1 rounded">
                {getStatusText()}
              </span>
            </div>

            {/* ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ í‘œì‹œ */}
            {interimTranscript && (
              <div className="absolute bottom-10 left-2 right-2">
                <div className="bg-black/70 text-white text-xs px-2 py-1 rounded">
                  ğŸ¤ &quot;{interimTranscript}&quot;
                </div>
              </div>
            )}
          </div>

          {/* í…ìŠ¤íŠ¸ ì…ë ¥ */}
          <div className="p-2 bg-zinc-800 border-t border-zinc-700">
            <div className="flex gap-2">
              <input
                className="flex-1 px-3 py-2 bg-zinc-700 text-white text-sm rounded-lg border border-zinc-600 focus:outline-none focus:border-purple-500 disabled:opacity-50"
                disabled={isLoading || isAvatarSpeaking}
                placeholder="ë˜ëŠ” í…ìŠ¤íŠ¸ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”..."
                type="text"
                value={inputText}
                onChange={(e) => setInputText(e.target.value)}
                onKeyDown={(e) =>
                  e.key === "Enter" && !e.shiftKey && handleSendMessage()
                }
              />
              <button
                className="px-4 py-2 bg-purple-600 hover:bg-purple-700 disabled:bg-zinc-600 text-white text-sm rounded-lg"
                disabled={isLoading || isAvatarSpeaking || !inputText.trim()}
                onClick={handleSendMessage}
              >
                {isLoading ? "..." : "ì „ì†¡"}
              </button>
            </div>
          </div>
        </div>
      ) : (
        <div className="w-full h-full flex items-center justify-center">
          {sessionState === StreamingAvatarSessionState.CONNECTING ? (
            <div className="flex flex-col items-center gap-3 text-white">
              <div className="w-8 h-8 border-2 border-purple-500 border-t-transparent rounded-full animate-spin" />
              <span className="text-sm">ì—°ê²° ì¤‘...</span>
            </div>
          ) : (
            <button
              className="px-6 py-3 bg-purple-600 hover:bg-purple-700 text-white rounded-full text-base font-medium shadow-lg"
              onClick={startSession}
            >
              ğŸ§  AI ë„ìš°ë¯¸ ì‹œì‘
            </button>
          )}
        </div>
      )}
    </div>
  );
}

export default function InteractiveAvatarWrapper() {
  return (
    <StreamingAvatarProvider basePath={process.env.NEXT_PUBLIC_BASE_API_URL}>
      <InteractiveAvatar />
    </StreamingAvatarProvider>
  );
}
